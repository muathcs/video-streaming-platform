{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2zPtDc6iTsL",
        "outputId": "cb7126b3-c5ab-4e90-abab-69afb44626b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  4  955k    4 39143    0     0  94320      0  0:00:10 --:--:--  0:00:10 95470\n",
            "100  955k  100  955k    0     0   887k      0  0:00:01  0:00:01 --:--:--  892k\n"
          ]
        }
      ],
      "source": [
        "! curl http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -o ml-latest-small.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CIu5FzOyjU2A"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Option 1: Using a SQL query to load the data\n",
        "query = \"\"\"\n",
        "SELECT * FROM public.\"Celeb\";\n",
        "\"\"\"\n",
        "\n",
        "# Step 3: Use pandas to load the SQL query result into a DataFrame\n",
        "celeb_df = pd.read_sql_query('SELECT * FROM public.\"Celeb\"', engine)\n",
        "\n",
        "# Now, movies_df contains the data from the 'movies' table in your database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2aMDkmMkHre",
        "outputId": "5b37f69b-030d-475f-cfdf-94d53e06a6ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dimensions of celebs dataframe are: (85, 15)\n"
          ]
        }
      ],
      "source": [
        "print('The dimensions of celebs dataframe are:', celeb_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gMHgvJaSlDyh",
        "outputId": "9e77828b-159f-4d6d-c637-45291dd2d857"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>celebid</th>\n",
              "      <th>displayname</th>\n",
              "      <th>username</th>\n",
              "      <th>followers</th>\n",
              "      <th>account</th>\n",
              "      <th>category</th>\n",
              "      <th>price</th>\n",
              "      <th>email</th>\n",
              "      <th>description</th>\n",
              "      <th>request_num</th>\n",
              "      <th>rating</th>\n",
              "      <th>uid</th>\n",
              "      <th>imgurl</th>\n",
              "      <th>document_with_idx</th>\n",
              "      <th>cluster_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2de6178b-9c19-4f61-aefc-8521cd9c4b2a</td>\n",
              "      <td>Tom Holland</td>\n",
              "      <td>Tom Holland</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>actor</td>\n",
              "      <td>29</td>\n",
              "      <td>tom-holland@gmail.com</td>\n",
              "      <td>British actor</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>FTgDBEmspGTbjlOxBl0XZxgmp8P2</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>'holland':2 'tom':1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9e60dc8d-c899-4f2b-b7a6-a697b8afd8ac</td>\n",
              "      <td>Will Ferrell</td>\n",
              "      <td>Will Ferrell</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>comedians</td>\n",
              "      <td>120</td>\n",
              "      <td>will-ferrell@gmail.com</td>\n",
              "      <td>American actor, comedian, screenwriter and pro...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>7cEenibVplPNibEXxZVZm7OViJF2</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>'ferrell':2 'will':1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c69459ca-b62b-48eb-8c60-32ef48b99c48</td>\n",
              "      <td>Jennifer Aniston</td>\n",
              "      <td>Jennifer Aniston</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>actors</td>\n",
              "      <td>93</td>\n",
              "      <td>jennifer-aniston@gmail.com</td>\n",
              "      <td>American actress (born 1969)</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>8gSO7PJwmlVZesHsmukCzd1x6gI3</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>'aniston':2 'jennifer':1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0f0e5997-1a89-4b3f-8b11-297c1611d789</td>\n",
              "      <td>Tommy Wiseau</td>\n",
              "      <td>Tommy Wiseau</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>actors</td>\n",
              "      <td>202</td>\n",
              "      <td>tommy-wiseau@gmail.com</td>\n",
              "      <td>Poland-born American director, actor, producer...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>dv6lrDFDIGfqxsbM9QLwcu5KzC33</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>'tommy':1 'wiseau':2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c1671604-28ca-4fde-aa14-502ffaaf5004</td>\n",
              "      <td>Millie Bobby Brown</td>\n",
              "      <td>Millie Bobby Brown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>actors</td>\n",
              "      <td>149</td>\n",
              "      <td>millie-bobby-brown@gmail.com</td>\n",
              "      <td>British actress (born. 2004)</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>qiwyrkAxlqMIaIKhtWvs4Oc5Fnl1</td>\n",
              "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
              "      <td>'bobby':2 'brown':3 'millie':1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                celebid         displayname  \\\n",
              "0  2de6178b-9c19-4f61-aefc-8521cd9c4b2a         Tom Holland   \n",
              "1  9e60dc8d-c899-4f2b-b7a6-a697b8afd8ac        Will Ferrell   \n",
              "2  c69459ca-b62b-48eb-8c60-32ef48b99c48    Jennifer Aniston   \n",
              "3  0f0e5997-1a89-4b3f-8b11-297c1611d789        Tommy Wiseau   \n",
              "4  c1671604-28ca-4fde-aa14-502ffaaf5004  Millie Bobby Brown   \n",
              "\n",
              "             username  followers account   category  price  \\\n",
              "0         Tom Holland        NaN    None      actor     29   \n",
              "1        Will Ferrell        NaN    None  comedians    120   \n",
              "2    Jennifer Aniston        NaN    None     actors     93   \n",
              "3        Tommy Wiseau        NaN    None     actors    202   \n",
              "4  Millie Bobby Brown        NaN    None     actors    149   \n",
              "\n",
              "                          email  \\\n",
              "0         tom-holland@gmail.com   \n",
              "1        will-ferrell@gmail.com   \n",
              "2    jennifer-aniston@gmail.com   \n",
              "3        tommy-wiseau@gmail.com   \n",
              "4  millie-bobby-brown@gmail.com   \n",
              "\n",
              "                                         description request_num rating  \\\n",
              "0                                      British actor        None   None   \n",
              "1  American actor, comedian, screenwriter and pro...        None   None   \n",
              "2                       American actress (born 1969)        None   None   \n",
              "3  Poland-born American director, actor, producer...        None   None   \n",
              "4                       British actress (born. 2004)        None   None   \n",
              "\n",
              "                            uid  \\\n",
              "0  FTgDBEmspGTbjlOxBl0XZxgmp8P2   \n",
              "1  7cEenibVplPNibEXxZVZm7OViJF2   \n",
              "2  8gSO7PJwmlVZesHsmukCzd1x6gI3   \n",
              "3  dv6lrDFDIGfqxsbM9QLwcu5KzC33   \n",
              "4  qiwyrkAxlqMIaIKhtWvs4Oc5Fnl1   \n",
              "\n",
              "                                              imgurl  \\\n",
              "0  https://upload.wikimedia.org/wikipedia/commons...   \n",
              "1  https://upload.wikimedia.org/wikipedia/commons...   \n",
              "2  https://upload.wikimedia.org/wikipedia/commons...   \n",
              "3  https://upload.wikimedia.org/wikipedia/commons...   \n",
              "4  https://upload.wikimedia.org/wikipedia/commons...   \n",
              "\n",
              "                document_with_idx  cluster_id  \n",
              "0             'holland':2 'tom':1           5  \n",
              "1            'ferrell':2 'will':1           4  \n",
              "2        'aniston':2 'jennifer':1           0  \n",
              "3            'tommy':1 'wiseau':2           0  \n",
              "4  'bobby':2 'brown':3 'millie':1           0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Take a look at movies_df\n",
        "celeb_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCSzmUeknLPX",
        "outputId": "547d8be8-27ea-4566-f969-122dcb16752f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique celebs: 85\n",
            "The full rating matrix will have: 7225 elements.\n",
            "----------\n",
            "Therefore:  1.1764705882352942 % of the matrix is filled.\n"
          ]
        }
      ],
      "source": [
        "# Movie ID to movie name mapping\n",
        "# movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
        "# n_users = len(movies_df.movieId.unique())\n",
        "n_items = len(celeb_df.celebid.unique())\n",
        "print(\"Number of unique celebs:\", n_items)\n",
        "print(\"The full rating matrix will have:\", n_items*n_items, 'elements.')\n",
        "print('----------')\n",
        "print(\"Therefore: \", len(celeb_df) / (n_items*n_items) * 100, '% of the matrix is filled.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZoDrLO6ppdHa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Placeholder for the number of users\n",
        "n_users_placeholder = 1  # since we don't have user data\n",
        "\n",
        "\n",
        "class MatrixFactorization(torch.nn.Module):\n",
        "    def __init__(self, n_items, n_factors=20):\n",
        "        super().__init__()\n",
        "        # Since we don't have actual user data, we won't use user_factors in this model\n",
        "        # create item embeddings\n",
        "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
        "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
        "\n",
        "    def forward(self, items):\n",
        "        return self.item_factors(items)\n",
        "\n",
        "# You would then instantiate this model using n_items\n",
        "model = MatrixFactorization(n_items=n_items)\n",
        "\n",
        "\n",
        "\n",
        "# And use it to generate embeddings for the movies only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6NYfi1eIpt5-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import torch\n",
        "\n",
        "# Note: This approach assumes we are recommending based on genre similarity only.\n",
        "\n",
        "class Loader(Dataset):\n",
        "    def __init__(self, celeb_df):\n",
        "        # Process genres into a binary matrix\n",
        "        self.celebs = celeb_df.copy()\n",
        "        self.celebs['category'] = self.celebs['category'].str.split('|')\n",
        "\n",
        "        # Binarizing the genres - each genre gets a separate column\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.genres_matrix = self.mlb.fit_transform(self.celebs['category'])\n",
        "\n",
        "        # Convert to torch tensors\n",
        "        self.x = torch.tensor(self.genres_matrix, dtype=torch.float32)\n",
        "\n",
        "        # Extract all movie IDs\n",
        "        celebs = self.celebs.celebid.unique()\n",
        "\n",
        "        #--- Producing new continuous IDs for movies ---\n",
        "        self.movieid2idx = {o:i for i, o in enumerate(celebs)}\n",
        "        self.idx2movieid = {i:o for o, i in self.movieid2idx.items()}\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # There's no y tensor since we are not using user ratings\n",
        "        return self.x[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.celebs)\n",
        "\n",
        "# Create instance of Loader with movies_df\n",
        "# loader = Loader(celeb_df=celeb_df)\n",
        "\n",
        "# Now, loader can be used to get genre feature vectors for each movie\n",
        "# For example:\n",
        "# movie_features = loader[0] # This will be the feature vector of the first movie\n",
        "\n",
        "# And you can use DataLoader as needed:\n",
        "# data_loader = DataLoader(loader, batch_size=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8cXT5f9qrBt",
        "outputId": "e88ac9f0-3df3-499b-da42-620d3bc8ac67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is running on GPU: False\n",
            "MatrixFactorization(\n",
            "  (item_factors): Embedding(85, 8)\n",
            ")\n",
            "item_factors.weight tensor([[0.0149, 0.0317, 0.0257, 0.0282, 0.0273, 0.0298, 0.0378, 0.0025],\n",
            "        [0.0193, 0.0429, 0.0421, 0.0050, 0.0273, 0.0054, 0.0123, 0.0309],\n",
            "        [0.0373, 0.0436, 0.0161, 0.0323, 0.0398, 0.0154, 0.0306, 0.0214],\n",
            "        [0.0476, 0.0322, 0.0410, 0.0101, 0.0426, 0.0069, 0.0434, 0.0377],\n",
            "        [0.0279, 0.0145, 0.0221, 0.0327, 0.0474, 0.0223, 0.0122, 0.0259],\n",
            "        [0.0032, 0.0202, 0.0459, 0.0165, 0.0486, 0.0123, 0.0230, 0.0055],\n",
            "        [0.0221, 0.0196, 0.0418, 0.0142, 0.0168, 0.0183, 0.0020, 0.0293],\n",
            "        [0.0225, 0.0292, 0.0221, 0.0362, 0.0211, 0.0345, 0.0076, 0.0179],\n",
            "        [0.0470, 0.0309, 0.0250, 0.0192, 0.0224, 0.0389, 0.0333, 0.0364],\n",
            "        [0.0158, 0.0234, 0.0204, 0.0065, 0.0033, 0.0469, 0.0223, 0.0268],\n",
            "        [0.0208, 0.0263, 0.0338, 0.0056, 0.0064, 0.0049, 0.0114, 0.0433],\n",
            "        [0.0353, 0.0275, 0.0165, 0.0201, 0.0202, 0.0232, 0.0343, 0.0362],\n",
            "        [0.0291, 0.0173, 0.0409, 0.0106, 0.0174, 0.0419, 0.0065, 0.0381],\n",
            "        [0.0018, 0.0329, 0.0465, 0.0395, 0.0498, 0.0199, 0.0221, 0.0397],\n",
            "        [0.0309, 0.0109, 0.0496, 0.0071, 0.0128, 0.0050, 0.0375, 0.0144],\n",
            "        [0.0397, 0.0282, 0.0456, 0.0227, 0.0084, 0.0046, 0.0421, 0.0245],\n",
            "        [0.0195, 0.0487, 0.0381, 0.0408, 0.0182, 0.0099, 0.0418, 0.0039],\n",
            "        [0.0098, 0.0445, 0.0065, 0.0201, 0.0447, 0.0153, 0.0347, 0.0157],\n",
            "        [0.0303, 0.0412, 0.0066, 0.0045, 0.0450, 0.0338, 0.0276, 0.0379],\n",
            "        [0.0328, 0.0426, 0.0351, 0.0480, 0.0262, 0.0159, 0.0022, 0.0174],\n",
            "        [0.0204, 0.0314, 0.0048, 0.0470, 0.0267, 0.0410, 0.0180, 0.0154],\n",
            "        [0.0465, 0.0103, 0.0280, 0.0028, 0.0459, 0.0250, 0.0049, 0.0158],\n",
            "        [0.0420, 0.0041, 0.0493, 0.0018, 0.0010, 0.0243, 0.0162, 0.0318],\n",
            "        [0.0200, 0.0231, 0.0149, 0.0104, 0.0017, 0.0293, 0.0332, 0.0194],\n",
            "        [0.0190, 0.0105, 0.0036, 0.0008, 0.0298, 0.0006, 0.0381, 0.0118],\n",
            "        [0.0258, 0.0019, 0.0101, 0.0319, 0.0217, 0.0091, 0.0482, 0.0087],\n",
            "        [0.0021, 0.0192, 0.0477, 0.0396, 0.0374, 0.0311, 0.0212, 0.0364],\n",
            "        [0.0372, 0.0206, 0.0131, 0.0285, 0.0125, 0.0238, 0.0473, 0.0120],\n",
            "        [0.0440, 0.0495, 0.0036, 0.0459, 0.0178, 0.0054, 0.0289, 0.0340],\n",
            "        [0.0330, 0.0077, 0.0295, 0.0383, 0.0189, 0.0187, 0.0346, 0.0438],\n",
            "        [0.0291, 0.0314, 0.0441, 0.0296, 0.0157, 0.0376, 0.0054, 0.0342],\n",
            "        [0.0213, 0.0265, 0.0193, 0.0097, 0.0206, 0.0059, 0.0127, 0.0132],\n",
            "        [0.0157, 0.0080, 0.0410, 0.0286, 0.0194, 0.0226, 0.0438, 0.0359],\n",
            "        [0.0160, 0.0223, 0.0324, 0.0290, 0.0345, 0.0228, 0.0491, 0.0173],\n",
            "        [0.0223, 0.0297, 0.0470, 0.0471, 0.0216, 0.0133, 0.0056, 0.0245],\n",
            "        [0.0030, 0.0349, 0.0306, 0.0039, 0.0454, 0.0465, 0.0478, 0.0432],\n",
            "        [0.0407, 0.0471, 0.0002, 0.0146, 0.0096, 0.0358, 0.0232, 0.0376],\n",
            "        [0.0175, 0.0214, 0.0423, 0.0071, 0.0366, 0.0458, 0.0215, 0.0466],\n",
            "        [0.0070, 0.0396, 0.0096, 0.0025, 0.0318, 0.0141, 0.0474, 0.0349],\n",
            "        [0.0238, 0.0205, 0.0241, 0.0052, 0.0357, 0.0198, 0.0336, 0.0499],\n",
            "        [0.0334, 0.0093, 0.0273, 0.0251, 0.0172, 0.0411, 0.0015, 0.0080],\n",
            "        [0.0157, 0.0320, 0.0335, 0.0247, 0.0381, 0.0077, 0.0464, 0.0007],\n",
            "        [0.0044, 0.0008, 0.0067, 0.0172, 0.0059, 0.0203, 0.0249, 0.0247],\n",
            "        [0.0221, 0.0429, 0.0297, 0.0455, 0.0389, 0.0468, 0.0167, 0.0490],\n",
            "        [0.0220, 0.0068, 0.0051, 0.0022, 0.0091, 0.0259, 0.0179, 0.0317],\n",
            "        [0.0033, 0.0259, 0.0154, 0.0312, 0.0063, 0.0080, 0.0349, 0.0115],\n",
            "        [0.0193, 0.0487, 0.0228, 0.0059, 0.0172, 0.0154, 0.0474, 0.0397],\n",
            "        [0.0243, 0.0062, 0.0225, 0.0290, 0.0207, 0.0111, 0.0218, 0.0099],\n",
            "        [0.0018, 0.0143, 0.0149, 0.0324, 0.0382, 0.0177, 0.0314, 0.0265],\n",
            "        [0.0378, 0.0305, 0.0434, 0.0237, 0.0164, 0.0324, 0.0127, 0.0066],\n",
            "        [0.0379, 0.0124, 0.0034, 0.0293, 0.0375, 0.0148, 0.0418, 0.0193],\n",
            "        [0.0466, 0.0310, 0.0072, 0.0192, 0.0057, 0.0125, 0.0413, 0.0068],\n",
            "        [0.0012, 0.0152, 0.0216, 0.0219, 0.0424, 0.0102, 0.0291, 0.0374],\n",
            "        [0.0455, 0.0187, 0.0369, 0.0289, 0.0174, 0.0223, 0.0068, 0.0189],\n",
            "        [0.0236, 0.0427, 0.0082, 0.0195, 0.0111, 0.0262, 0.0403, 0.0319],\n",
            "        [0.0238, 0.0092, 0.0453, 0.0327, 0.0401, 0.0421, 0.0209, 0.0171],\n",
            "        [0.0294, 0.0107, 0.0093, 0.0125, 0.0342, 0.0273, 0.0035, 0.0086],\n",
            "        [0.0097, 0.0029, 0.0158, 0.0076, 0.0394, 0.0364, 0.0339, 0.0479],\n",
            "        [0.0273, 0.0150, 0.0011, 0.0167, 0.0202, 0.0333, 0.0152, 0.0034],\n",
            "        [0.0344, 0.0477, 0.0423, 0.0018, 0.0173, 0.0134, 0.0294, 0.0074],\n",
            "        [0.0314, 0.0461, 0.0238, 0.0018, 0.0393, 0.0096, 0.0402, 0.0244],\n",
            "        [0.0101, 0.0499, 0.0137, 0.0183, 0.0146, 0.0031, 0.0424, 0.0206],\n",
            "        [0.0273, 0.0103, 0.0047, 0.0453, 0.0191, 0.0213, 0.0379, 0.0380],\n",
            "        [0.0220, 0.0488, 0.0050, 0.0317, 0.0476, 0.0450, 0.0113, 0.0380],\n",
            "        [0.0402, 0.0235, 0.0028, 0.0186, 0.0329, 0.0011, 0.0313, 0.0052],\n",
            "        [0.0227, 0.0092, 0.0343, 0.0423, 0.0482, 0.0007, 0.0469, 0.0012],\n",
            "        [0.0241, 0.0336, 0.0169, 0.0174, 0.0094, 0.0335, 0.0185, 0.0453],\n",
            "        [0.0244, 0.0031, 0.0318, 0.0475, 0.0495, 0.0306, 0.0215, 0.0133],\n",
            "        [0.0179, 0.0366, 0.0048, 0.0309, 0.0248, 0.0337, 0.0388, 0.0434],\n",
            "        [0.0106, 0.0306, 0.0214, 0.0446, 0.0466, 0.0285, 0.0297, 0.0322],\n",
            "        [0.0056, 0.0467, 0.0392, 0.0340, 0.0239, 0.0172, 0.0254, 0.0192],\n",
            "        [0.0282, 0.0287, 0.0155, 0.0295, 0.0285, 0.0271, 0.0202, 0.0202],\n",
            "        [0.0368, 0.0301, 0.0056, 0.0287, 0.0063, 0.0262, 0.0125, 0.0358],\n",
            "        [0.0479, 0.0359, 0.0181, 0.0054, 0.0123, 0.0490, 0.0110, 0.0004],\n",
            "        [0.0116, 0.0445, 0.0346, 0.0493, 0.0314, 0.0323, 0.0275, 0.0284],\n",
            "        [0.0111, 0.0087, 0.0488, 0.0100, 0.0356, 0.0096, 0.0063, 0.0040],\n",
            "        [0.0373, 0.0094, 0.0229, 0.0158, 0.0291, 0.0274, 0.0004, 0.0462],\n",
            "        [0.0395, 0.0427, 0.0273, 0.0392, 0.0472, 0.0360, 0.0268, 0.0148],\n",
            "        [0.0233, 0.0473, 0.0221, 0.0423, 0.0476, 0.0161, 0.0459, 0.0190],\n",
            "        [0.0013, 0.0009, 0.0010, 0.0231, 0.0421, 0.0412, 0.0006, 0.0481],\n",
            "        [0.0464, 0.0233, 0.0128, 0.0420, 0.0186, 0.0398, 0.0340, 0.0409],\n",
            "        [0.0257, 0.0464, 0.0421, 0.0446, 0.0033, 0.0269, 0.0235, 0.0354],\n",
            "        [0.0114, 0.0296, 0.0251, 0.0291, 0.0044, 0.0081, 0.0197, 0.0309],\n",
            "        [0.0072, 0.0217, 0.0160, 0.0006, 0.0321, 0.0272, 0.0216, 0.0128],\n",
            "        [0.0259, 0.0063, 0.0373, 0.0197, 0.0314, 0.0249, 0.0091, 0.0361]])\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 128\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "print(\"Is running on GPU:\", cuda)\n",
        "\n",
        "model = MatrixFactorization(n_items=n_items, n_factors=8)\n",
        "print(model)\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "# GPU enable if you have a GPU...\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "# MSE loss\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# ADAM optimizier\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Train data\n",
        "train_set = Loader(celeb_df)\n",
        "train_loader = DataLoader(train_set, 128, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5ce1f0eb6ca40e09d5c5da0e567c2fe",
            "840a2bf5ad2745a0aecfb73d1c55d677",
            "a85d1ee03e5d45f38a10b928005ea198",
            "53e4a66f79d8456fb13950f1bf76eca3",
            "43b62a2b236044dc8dc6e89a52aef820",
            "b991c323daee49d8a1daf6ba23220d4f",
            "593acbf2a37348ccbd9aed80ef8e4400",
            "390ed2fecc544e03910d576281717732",
            "ecfdd534dfca46c4aefd101e5ebf9e33",
            "70aab97fc78f4eaa8b9a112950c9f3e2",
            "8654b09ceaec422ba4f174b3a62f9b86"
          ]
        },
        "id": "K1cZqFG4q9y0",
        "outputId": "b524b94f-50a2-4b90-97e0-5a1ad3d01e48"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a9f88c53c6471793e1506c8886f18b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/128 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter #0, Loss: 0.69267338514328\n",
            "Iter #1, Loss: 0.6870102882385254\n",
            "Iter #2, Loss: 0.6812304854393005\n",
            "Iter #3, Loss: 0.6753911375999451\n",
            "Iter #4, Loss: 0.669285237789154\n",
            "Iter #5, Loss: 0.6630070805549622\n",
            "Iter #6, Loss: 0.656467080116272\n",
            "Iter #7, Loss: 0.6495956182479858\n",
            "Iter #8, Loss: 0.6423742175102234\n",
            "Iter #9, Loss: 0.6345275640487671\n",
            "Iter #10, Loss: 0.6259585618972778\n",
            "Iter #11, Loss: 0.6165583729743958\n",
            "Iter #12, Loss: 0.6061915159225464\n",
            "Iter #13, Loss: 0.5948249101638794\n",
            "Iter #14, Loss: 0.5823817253112793\n",
            "Iter #15, Loss: 0.5686280131340027\n",
            "Iter #16, Loss: 0.553763747215271\n",
            "Iter #17, Loss: 0.5376943945884705\n",
            "Iter #18, Loss: 0.5205128788948059\n",
            "Iter #19, Loss: 0.5022600889205933\n",
            "Iter #20, Loss: 0.48292726278305054\n",
            "Iter #21, Loss: 0.4627256393432617\n",
            "Iter #22, Loss: 0.44187572598457336\n",
            "Iter #23, Loss: 0.4206685721874237\n",
            "Iter #24, Loss: 0.3994947671890259\n",
            "Iter #25, Loss: 0.3787635862827301\n",
            "Iter #26, Loss: 0.35895565152168274\n",
            "Iter #27, Loss: 0.3405197262763977\n",
            "Iter #28, Loss: 0.3239142894744873\n",
            "Iter #29, Loss: 0.309423565864563\n",
            "Iter #30, Loss: 0.29722002148628235\n",
            "Iter #31, Loss: 0.2873745560646057\n",
            "Iter #32, Loss: 0.2797527015209198\n",
            "Iter #33, Loss: 0.27406954765319824\n",
            "Iter #34, Loss: 0.26994752883911133\n",
            "Iter #35, Loss: 0.26696979999542236\n",
            "Iter #36, Loss: 0.26471632719039917\n",
            "Iter #37, Loss: 0.26281115412712097\n",
            "Iter #38, Loss: 0.2609226107597351\n",
            "Iter #39, Loss: 0.25885260105133057\n",
            "Iter #40, Loss: 0.2564595937728882\n",
            "Iter #41, Loss: 0.2536068558692932\n",
            "Iter #42, Loss: 0.2503044009208679\n",
            "Iter #43, Loss: 0.24657630920410156\n",
            "Iter #44, Loss: 0.242509126663208\n",
            "Iter #45, Loss: 0.23818300664424896\n",
            "Iter #46, Loss: 0.2336682230234146\n",
            "Iter #47, Loss: 0.22909630835056305\n",
            "Iter #48, Loss: 0.22458702325820923\n",
            "Iter #49, Loss: 0.22014537453651428\n",
            "Iter #50, Loss: 0.21579881012439728\n",
            "Iter #51, Loss: 0.21159197390079498\n",
            "Iter #52, Loss: 0.2075490653514862\n",
            "Iter #53, Loss: 0.2036902904510498\n",
            "Iter #54, Loss: 0.19998079538345337\n",
            "Iter #55, Loss: 0.19637718796730042\n",
            "Iter #56, Loss: 0.19286860525608063\n",
            "Iter #57, Loss: 0.18937887251377106\n",
            "Iter #58, Loss: 0.18592482805252075\n",
            "Iter #59, Loss: 0.18248251080513\n",
            "Iter #60, Loss: 0.17901836335659027\n",
            "Iter #61, Loss: 0.17553174495697021\n",
            "Iter #62, Loss: 0.17200954258441925\n",
            "Iter #63, Loss: 0.16849465668201447\n",
            "Iter #64, Loss: 0.16501693427562714\n",
            "Iter #65, Loss: 0.16159296035766602\n",
            "Iter #66, Loss: 0.15820948779582977\n",
            "Iter #67, Loss: 0.15492753684520721\n",
            "Iter #68, Loss: 0.15176235139369965\n",
            "Iter #69, Loss: 0.1487484872341156\n",
            "Iter #70, Loss: 0.14587727189064026\n",
            "Iter #71, Loss: 0.14317135512828827\n",
            "Iter #72, Loss: 0.14061538875102997\n",
            "Iter #73, Loss: 0.13822521269321442\n",
            "Iter #74, Loss: 0.13599109649658203\n",
            "Iter #75, Loss: 0.13392288982868195\n",
            "Iter #76, Loss: 0.1320038139820099\n",
            "Iter #77, Loss: 0.13023892045021057\n",
            "Iter #78, Loss: 0.12861652672290802\n",
            "Iter #79, Loss: 0.12709224224090576\n",
            "Iter #80, Loss: 0.12566660344600677\n",
            "Iter #81, Loss: 0.12432027608156204\n",
            "Iter #82, Loss: 0.12302820384502411\n",
            "Iter #83, Loss: 0.12176837772130966\n",
            "Iter #84, Loss: 0.1205526813864708\n",
            "Iter #85, Loss: 0.11936842650175095\n",
            "Iter #86, Loss: 0.1182127371430397\n",
            "Iter #87, Loss: 0.11705953627824783\n",
            "Iter #88, Loss: 0.11589207500219345\n",
            "Iter #89, Loss: 0.11471835523843765\n",
            "Iter #90, Loss: 0.11353234946727753\n",
            "Iter #91, Loss: 0.11231662333011627\n",
            "Iter #92, Loss: 0.11107748001813889\n",
            "Iter #93, Loss: 0.10982657223939896\n",
            "Iter #94, Loss: 0.10854080319404602\n",
            "Iter #95, Loss: 0.10723411291837692\n",
            "Iter #96, Loss: 0.10589657723903656\n",
            "Iter #97, Loss: 0.10452112555503845\n",
            "Iter #98, Loss: 0.10309822112321854\n",
            "Iter #99, Loss: 0.10161857306957245\n",
            "Iter #100, Loss: 0.10008690506219864\n",
            "Iter #101, Loss: 0.09853779524564743\n",
            "Iter #102, Loss: 0.09695122390985489\n",
            "Iter #103, Loss: 0.09530662000179291\n",
            "Iter #104, Loss: 0.09362189471721649\n",
            "Iter #105, Loss: 0.09188215434551239\n",
            "Iter #106, Loss: 0.09012216329574585\n",
            "Iter #107, Loss: 0.08836041390895844\n",
            "Iter #108, Loss: 0.08656430244445801\n",
            "Iter #109, Loss: 0.08472464233636856\n",
            "Iter #110, Loss: 0.08284857124090195\n",
            "Iter #111, Loss: 0.08093519508838654\n",
            "Iter #112, Loss: 0.07900083065032959\n",
            "Iter #113, Loss: 0.07703697681427002\n",
            "Iter #114, Loss: 0.07505913078784943\n",
            "Iter #115, Loss: 0.07308927178382874\n",
            "Iter #116, Loss: 0.07111617922782898\n",
            "Iter #117, Loss: 0.06913558393716812\n",
            "Iter #118, Loss: 0.06715618073940277\n",
            "Iter #119, Loss: 0.0652167871594429\n",
            "Iter #120, Loss: 0.06331177055835724\n",
            "Iter #121, Loss: 0.06143616512417793\n",
            "Iter #122, Loss: 0.05959436297416687\n",
            "Iter #123, Loss: 0.05779237672686577\n",
            "Iter #124, Loss: 0.0560188814997673\n",
            "Iter #125, Loss: 0.05427314713597298\n",
            "Iter #126, Loss: 0.05254795402288437\n",
            "Iter #127, Loss: 0.05086241289973259\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class ContentBasedModel(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(ContentBasedModel, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(num_features, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_features),\n",
        "            nn.Sigmoid()  # Using sigmoid because the genre vector is binary\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "model = ContentBasedModel(num_features=8)\n",
        "\n",
        "# If CUDA is available, move the model to the GPU\n",
        "if cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "# Loss function\n",
        "loss_fn = nn.BCELoss()  # Binary Cross-Entropy Loss for the binary genre vector\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 128\n",
        "for it in tqdm(range(num_epochs)):\n",
        "    losses = []\n",
        "    for x in train_loader:\n",
        "        # Move tensors to the correct device\n",
        "        if cuda:\n",
        "            x = x.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(outputs, x)  # The target is to reconstruct the input genre vector\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    print(f\"Iter #{it}, Loss: {sum(losses) / len(losses)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXUY31Tvq_r5",
        "outputId": "e664e36c-2bec-4666-9e71-b82316f7f1df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder.0.weight tensor([[ 0.0051,  0.1511,  0.0213,  ...,  0.3058,  0.2362,  0.2447],\n",
            "        [ 0.0875,  0.2405,  0.1308,  ..., -0.1007, -0.1576, -0.0403],\n",
            "        [ 0.1872, -0.3253,  0.0492,  ..., -0.3034,  0.0852,  0.3244],\n",
            "        ...,\n",
            "        [ 0.0399, -0.1278,  0.3037,  ...,  0.3375, -0.2915,  0.0139],\n",
            "        [-0.0641,  0.0816,  0.0133,  ...,  0.1393, -0.1455, -0.0451],\n",
            "        [ 0.2553,  0.0172, -0.2035,  ...,  0.0765, -0.3103, -0.2893]])\n",
            "encoder.0.bias tensor([ 3.2291e-01,  3.2412e-01,  2.8540e-01,  3.1495e-01,  1.3390e-01,\n",
            "         1.8497e-01,  1.4197e-01, -1.6671e-01, -7.0359e-02, -1.8827e-01,\n",
            "        -2.7083e-02,  8.7518e-02, -1.2228e-01, -4.6244e-02,  2.7584e-01,\n",
            "         2.2971e-01,  1.1212e-01,  3.8816e-01, -9.0158e-03, -3.0319e-01,\n",
            "         3.4967e-02,  2.8424e-02,  1.0926e-01,  3.2430e-01,  3.0630e-01,\n",
            "         1.3447e-02,  1.4375e-01, -1.1032e-01, -9.3107e-02, -7.1630e-02,\n",
            "        -1.3333e-01, -3.3539e-01,  1.4323e-01,  3.8243e-01,  3.8967e-02,\n",
            "         3.8800e-01,  3.2367e-01, -1.1997e-01,  1.5296e-01,  2.3581e-01,\n",
            "         1.1246e-01, -9.0708e-02, -2.2365e-01,  2.7364e-01, -1.9621e-01,\n",
            "        -1.0845e-01,  4.2426e-02, -4.7569e-03, -1.5673e-01, -5.2726e-02,\n",
            "        -3.0329e-02,  2.8599e-01, -2.0501e-01,  6.4870e-02, -3.2109e-01,\n",
            "         2.3170e-01,  3.3260e-01,  8.5410e-03,  3.5855e-01,  3.1246e-01,\n",
            "         2.8518e-01,  1.2622e-01,  1.1796e-01, -3.5286e-01, -6.7157e-02,\n",
            "        -1.3163e-01, -1.1671e-01,  1.2799e-01,  2.0225e-01, -2.1587e-01,\n",
            "         1.5255e-01, -1.4294e-01,  1.2142e-01, -6.2666e-02, -2.5000e-01,\n",
            "         2.0859e-01,  3.6320e-01, -7.4479e-02,  1.1055e-01,  1.3164e-01,\n",
            "         2.5653e-03,  5.1402e-02,  1.7560e-01, -2.8296e-01,  2.0121e-01,\n",
            "         8.2575e-02,  1.7530e-01,  3.1874e-01,  3.4921e-01,  2.8580e-01,\n",
            "         1.3851e-01,  1.4576e-01,  3.6383e-01,  1.4688e-01, -2.3114e-02,\n",
            "         1.1936e-01,  1.4063e-01, -1.1150e-01, -3.2955e-01,  2.1285e-01,\n",
            "         3.6431e-04,  2.6323e-01,  2.0278e-01, -1.3823e-01,  9.1928e-02,\n",
            "        -1.2308e-02, -1.8762e-01,  8.5575e-02,  6.9885e-02,  2.3364e-01,\n",
            "        -2.3087e-01, -1.2472e-03,  2.7516e-01, -4.5260e-02,  1.5613e-01,\n",
            "         3.3373e-01, -5.3457e-03,  3.5328e-01,  6.4465e-02, -2.6561e-01,\n",
            "        -3.0808e-01, -2.5669e-01,  3.6813e-01,  1.7171e-01,  2.7258e-01,\n",
            "         1.2557e-01, -5.0329e-02,  2.0748e-01])\n",
            "encoder.2.weight tensor([[ 0.1036, -0.0422, -0.0015,  ...,  0.1274, -0.0176, -0.0668],\n",
            "        [-0.0839, -0.0539, -0.0777,  ...,  0.0685,  0.0366, -0.0068],\n",
            "        [ 0.0951,  0.1010,  0.1136,  ...,  0.0431, -0.0508, -0.0940],\n",
            "        ...,\n",
            "        [ 0.0490, -0.0713,  0.0385,  ..., -0.0552, -0.0120,  0.0583],\n",
            "        [ 0.0137, -0.0705, -0.0689,  ..., -0.0358, -0.0191, -0.0226],\n",
            "        [-0.0303, -0.0091,  0.1157,  ...,  0.0194, -0.1397, -0.0904]])\n",
            "encoder.2.bias tensor([ 0.1280, -0.0798, -0.0410,  0.0594,  0.0619,  0.1183, -0.0263, -0.0143,\n",
            "         0.0477, -0.0730,  0.0320, -0.0446,  0.1329,  0.0881, -0.0803,  0.0931,\n",
            "         0.1272, -0.0294,  0.0720,  0.0157,  0.0992, -0.0146, -0.0084,  0.1144,\n",
            "         0.0129,  0.0623,  0.0354,  0.0244,  0.0489,  0.0281, -0.0523, -0.0234,\n",
            "         0.0603,  0.0173, -0.0382,  0.0437,  0.1179,  0.1077, -0.0048,  0.0609,\n",
            "         0.0196,  0.0124,  0.0049,  0.0676,  0.1038,  0.0726, -0.0455, -0.0433,\n",
            "         0.0556, -0.0153,  0.0584,  0.0352, -0.0208,  0.0639, -0.0381, -0.0848,\n",
            "         0.0538,  0.0756,  0.0948,  0.0948,  0.0694,  0.0006, -0.0871, -0.0196])\n",
            "decoder.0.weight tensor([[ 0.1689, -0.1128,  0.0359,  ...,  0.1007, -0.0899,  0.1321],\n",
            "        [ 0.1644,  0.0573,  0.0446,  ..., -0.1026, -0.0782,  0.0718],\n",
            "        [-0.0070,  0.1202, -0.1366,  ..., -0.1058,  0.0807, -0.0968],\n",
            "        ...,\n",
            "        [ 0.0225,  0.1199,  0.0808,  ...,  0.1018, -0.0323, -0.0381],\n",
            "        [-0.0872, -0.0467,  0.1521,  ..., -0.0705,  0.0324,  0.1737],\n",
            "        [ 0.1022,  0.0464,  0.0206,  ...,  0.0052, -0.0891,  0.0778]])\n",
            "decoder.0.bias tensor([ 0.1198,  0.0885,  0.0340, -0.0178, -0.0605, -0.0537,  0.0453, -0.0204,\n",
            "        -0.1431,  0.1378,  0.1104,  0.0176,  0.0572, -0.0658, -0.0300,  0.0624,\n",
            "         0.0623,  0.0503,  0.1177, -0.0449, -0.0894,  0.0454, -0.1114,  0.0077,\n",
            "        -0.0103, -0.0521,  0.0863,  0.0294, -0.0079, -0.0935, -0.0707, -0.0386,\n",
            "         0.1170,  0.1114,  0.1445,  0.0585,  0.0561,  0.0673,  0.1538, -0.0171,\n",
            "         0.0826,  0.0784, -0.0232,  0.0918,  0.0996, -0.0796,  0.0813, -0.0257,\n",
            "         0.1276,  0.0065,  0.0123,  0.1373, -0.0742,  0.0704, -0.1001, -0.0923,\n",
            "         0.0989,  0.0924, -0.0794, -0.0467,  0.0082,  0.1117, -0.0676, -0.0771,\n",
            "        -0.0428,  0.0648, -0.1288,  0.0672, -0.0154, -0.0757,  0.0161,  0.1191,\n",
            "         0.0477,  0.0688, -0.0090, -0.0890, -0.0931, -0.0104, -0.1316,  0.1118,\n",
            "        -0.0190,  0.0229, -0.0287, -0.0726, -0.0480, -0.1126, -0.0614,  0.0481,\n",
            "        -0.0642, -0.0078, -0.1104,  0.0802, -0.0218,  0.0718, -0.0843,  0.1534,\n",
            "         0.1308,  0.0291, -0.0363,  0.1060, -0.0848, -0.0683,  0.0879,  0.1442,\n",
            "        -0.0261, -0.0715,  0.0296,  0.1284,  0.1097,  0.0950,  0.0057, -0.0485,\n",
            "         0.0606,  0.0018, -0.1003, -0.0106, -0.0361,  0.0250, -0.0293, -0.1077,\n",
            "        -0.0659, -0.0013,  0.1209, -0.1027, -0.0579,  0.0085, -0.0771, -0.0341])\n",
            "decoder.2.weight tensor([[-0.1278,  0.0210,  0.0703,  ..., -0.0386, -0.0588,  0.0800],\n",
            "        [-0.0049, -0.0826,  0.0270,  ...,  0.0116, -0.0958, -0.0552],\n",
            "        [ 0.0187,  0.0186,  0.0930,  ...,  0.0246,  0.0995,  0.0037],\n",
            "        ...,\n",
            "        [-0.0277, -0.0059,  0.0070,  ...,  0.0143, -0.1485,  0.0727],\n",
            "        [-0.1102, -0.1386, -0.0009,  ...,  0.0606, -0.1683, -0.0426],\n",
            "        [-0.1287, -0.1219,  0.0718,  ...,  0.0486,  0.0918,  0.0369]])\n",
            "decoder.2.bias tensor([ 0.0392, -0.0915,  0.0557, -0.0267,  0.0191, -0.0867, -0.0226, -0.0044])\n"
          ]
        }
      ],
      "source": [
        "# By training the model, we will have tuned latent factors for movies and users.\n",
        "c = 0\n",
        "uw = 0\n",
        "iw = 0\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)\n",
        "        if c == 0:\n",
        "          uw = param.data\n",
        "          c +=1\n",
        "        else:\n",
        "          iw = param.data\n",
        "        #print('param_data', param_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Nc8f3uhmrKmP"
      },
      "outputs": [],
      "source": [
        "# Assuming that your model has an encoder which compresses the movie input to a lower-dimensional space\n",
        "# We will extract the output of the encoder to use as movie embeddings.\n",
        "\n",
        "# First, we must put the model in evaluation mode.\n",
        "model.eval()\n",
        "\n",
        "# Next, we will pass all movie data through the encoder to get the embeddings.\n",
        "# We disable gradient computation since we are not training now.\n",
        "with torch.no_grad():\n",
        "    # If your movies dataset is very large, this might not fit in memory.\n",
        "    # In such a case, you'd want to process the movies in batches and concatenate the results.\n",
        "    trained_movie_embeddings = model.encoder(train_set.x).cpu().numpy()\n",
        "\n",
        "# Now you have a numpy array `movie_embeddings` with the learned embeddings for your movies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clwcCchxrLUu",
        "outputId": "464ea4c8-f767-49e3-eaa0-d61d7a4bfbc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trained_movie_embeddings) # unique movie factor weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwfdf5BIr64m",
        "outputId": "c81de6f5-2bc9-456b-dcf2-f37267593bf2"
      },
      "outputs": [],
      "source": [
        "# Perform clustering\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=7, random_state=42)\n",
        "kmeans.fit(trained_movie_embeddings)  # your features array\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Assign cluster labels to DataFrame\n",
        "celeb_df['cluster_id'] = cluster_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ARYtmhbr_PN",
        "outputId": "4745013b-41ae-4f79-a0d0-7ca4b30366d6"
      },
      "outputs": [],
      "source": [
        "'''It can be seen here that the movies that are in the same cluster tend to have\n",
        "similar genres. Also note that the algorithm is unfamiliar with the movie name\n",
        "and only obtained the relationships by looking at the numbers representing how\n",
        "users have responded to the movie selections.'''\n",
        "import numpy as np\n",
        "\n",
        "for cluster in range(8):\n",
        "    print(\"Cluster #{}\".format(cluster))\n",
        "    movs = []\n",
        "    for i in np.where(kmeans.labels_ == cluster)[0]:\n",
        "        movid = train_set.idx2movieid[i]\n",
        "        # Filter the DataFrame for rows where 'celebid' matches 'movid'\n",
        "        filtered_df = celeb_df[celeb_df['celebid'] == movid]\n",
        "        # Get the count of such matches\n",
        "        rat_count = filtered_df.shape[0]  # This gives the number of rows matching the movid\n",
        "        if not filtered_df.empty:\n",
        "            # Example: Assuming you want to display the 'displayname' of the celebrity\n",
        "            movs.append((filtered_df.iloc[0]['displayname'], rat_count))\n",
        "        else:\n",
        "            print(f\"No data found for celebid: {movid}\")\n",
        "    for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
        "        print(\"\\t\", mov[0])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "update_queries = \"\\n\".join(\n",
        "    f\"UPDATE public.\\\"Celeb\\\" SET cluster_id = {row['cluster_id']} WHERE celebid = '{row['celebid']}';\"\n",
        "    for idx, row in celeb_df.iterrows()\n",
        ")\n",
        "\n",
        "print(update_queries)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "# Assuming 'engine' is your SQLAlchemy engine\n",
        "with engine.connect() as conn:\n",
        "    for query in update_queries.split('\\n'):\n",
        "        conn.execute(text(query))\n",
        "    conn.commit()  # Explicitly committing the transaction\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "390ed2fecc544e03910d576281717732": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b62a2b236044dc8dc6e89a52aef820": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e4a66f79d8456fb13950f1bf76eca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70aab97fc78f4eaa8b9a112950c9f3e2",
            "placeholder": "​",
            "style": "IPY_MODEL_8654b09ceaec422ba4f174b3a62f9b86",
            "value": " 128/128 [03:53&lt;00:00,  1.83s/it]"
          }
        },
        "593acbf2a37348ccbd9aed80ef8e4400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70aab97fc78f4eaa8b9a112950c9f3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840a2bf5ad2745a0aecfb73d1c55d677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b991c323daee49d8a1daf6ba23220d4f",
            "placeholder": "​",
            "style": "IPY_MODEL_593acbf2a37348ccbd9aed80ef8e4400",
            "value": "100%"
          }
        },
        "8654b09ceaec422ba4f174b3a62f9b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a85d1ee03e5d45f38a10b928005ea198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390ed2fecc544e03910d576281717732",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecfdd534dfca46c4aefd101e5ebf9e33",
            "value": 128
          }
        },
        "b991c323daee49d8a1daf6ba23220d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecfdd534dfca46c4aefd101e5ebf9e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5ce1f0eb6ca40e09d5c5da0e567c2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_840a2bf5ad2745a0aecfb73d1c55d677",
              "IPY_MODEL_a85d1ee03e5d45f38a10b928005ea198",
              "IPY_MODEL_53e4a66f79d8456fb13950f1bf76eca3"
            ],
            "layout": "IPY_MODEL_43b62a2b236044dc8dc6e89a52aef820"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
